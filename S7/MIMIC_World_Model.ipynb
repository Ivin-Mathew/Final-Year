{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700f6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 1: Setup and constants defined successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- 1. Define Constants ---\n",
    "# File paths based on your directory structure\n",
    "MIMIC_ICU_DIR = 'data/mimic-iv-clinical-database-demo-2.2/icu/'\n",
    "MIMIC_HOSP_DIR = 'data/mimic-iv-clinical-database-demo-2.2/hosp/'\n",
    "\n",
    "# Define the time window for bucketing data (in hours)\n",
    "TIME_BUCKET_SIZE = 4\n",
    "\n",
    "# --- Define itemids for the features you want ---\n",
    "# States (Vitals & Labs)\n",
    "ID_HEART_RATE = 220045\n",
    "ID_SYSTOLIC_BP = 220179\n",
    "ID_DIASTOLIC_BP = 220180\n",
    "ID_TEMPERATURE = 223761\n",
    "ID_LACTATE = 50813 # from d_labitems\n",
    "\n",
    "# Actions (Medications)\n",
    "ID_NOREPINEPHRINE = 221906 # Vasopressor\n",
    "ID_FLUID_BOLUS = 225158     # IV Fluid\n",
    "\n",
    "print(\"Cell 1: Setup and constants defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa62818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and filtering raw data...\n",
      "Cell 2: Raw data loaded and merged successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load and Merge Data Upfront ---\n",
    "print(\"Loading and filtering raw data...\")\n",
    "\n",
    "# ICU Stays (the source of truth for stay_id and intime)\n",
    "df_icu_stays = pd.read_csv(f'{MIMIC_ICU_DIR}icustays.csv.gz', usecols=['stay_id', 'subject_id', 'intime'])\n",
    "df_icu_stays['intime'] = pd.to_datetime(df_icu_stays['intime'])\n",
    "\n",
    "# Vitals from chartevents\n",
    "df_chartevents = pd.read_csv(f'{MIMIC_ICU_DIR}chartevents.csv.gz', usecols=['stay_id', 'charttime', 'itemid', 'valuenum'])\n",
    "state_vitals_ids = [ID_HEART_RATE, ID_SYSTOLIC_BP, ID_DIASTOLIC_BP, ID_TEMPERATURE]\n",
    "df_vitals_raw = df_chartevents[df_chartevents['itemid'].isin(state_vitals_ids)].copy()\n",
    "\n",
    "# Labs from labevents\n",
    "df_labevents = pd.read_csv(f'{MIMIC_HOSP_DIR}labevents.csv.gz', usecols=['subject_id', 'charttime', 'itemid', 'valuenum'])\n",
    "state_labs_ids = [ID_LACTATE]\n",
    "df_labs_raw = df_labevents[df_labevents['itemid'].isin(state_labs_ids)].copy()\n",
    "\n",
    "# Actions from inputevents\n",
    "df_inputevents = pd.read_csv(f'{MIMIC_ICU_DIR}inputevents.csv.gz', usecols=['stay_id', 'starttime', 'itemid', 'amount'])\n",
    "action_ids = [ID_NOREPINEPHRINE, ID_FLUID_BOLUS]\n",
    "df_actions_raw = df_inputevents[df_inputevents['itemid'].isin(action_ids)].copy()\n",
    "\n",
    "# --- Centralize all merges here ---\n",
    "# Add 'intime' to vitals and actions using their 'stay_id'\n",
    "df_vitals = pd.merge(df_vitals_raw, df_icu_stays, on='stay_id', how='inner')\n",
    "df_actions = pd.merge(df_actions_raw, df_icu_stays, on='stay_id', how='inner')\n",
    "\n",
    "# Add 'stay_id' and 'intime' to labs using their 'subject_id'\n",
    "df_labs = pd.merge(df_labs_raw, df_icu_stays, on='subject_id', how='inner')\n",
    "\n",
    "print(\"Cell 2: Raw data loaded and merged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760ba70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating data into time buckets...\n",
      "Cell 3: Data aggregation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Simplified Time-Bucket and Aggregate ---\n",
    "def simplified_process_and_aggregate(df, time_col, value_col, item_id, feature_name):\n",
    "    \"\"\"A simplified function that assumes df already has stay_id and intime.\"\"\"\n",
    "    df_filtered = df[df['itemid'] == item_id].copy()\n",
    "    df_filtered[time_col] = pd.to_datetime(df_filtered[time_col])\n",
    "    \n",
    "    # Calculate hours from admission (intime is already present)\n",
    "    df_filtered['hours_in'] = (df_filtered[time_col] - df_filtered['intime']).dt.total_seconds() / 3600\n",
    "    df_filtered['time_bucket'] = (df_filtered['hours_in'] // TIME_BUCKET_SIZE).astype(int)\n",
    "    \n",
    "    # Aggregate by taking the mean value in each bucket\n",
    "    df_agg = df_filtered.groupby(['stay_id', 'time_bucket'])[value_col].mean().reset_index()\n",
    "    df_agg = df_agg.rename(columns={value_col: feature_name})\n",
    "    \n",
    "    return df_agg\n",
    "\n",
    "print(\"Aggregating data into time buckets...\")\n",
    "# Process States\n",
    "df_hr = simplified_process_and_aggregate(df_vitals, 'charttime', 'valuenum', ID_HEART_RATE, 'heart_rate')\n",
    "df_sbp = simplified_process_and_aggregate(df_vitals, 'charttime', 'valuenum', ID_SYSTOLIC_BP, 'systolic_bp')\n",
    "df_dbp = simplified_process_and_aggregate(df_vitals, 'charttime', 'valuenum', ID_DIASTOLIC_BP, 'diastolic_bp')\n",
    "df_temp = simplified_process_and_aggregate(df_vitals, 'charttime', 'valuenum', ID_TEMPERATURE, 'temperature')\n",
    "df_lactate = simplified_process_and_aggregate(df_labs, 'charttime', 'valuenum', ID_LACTATE, 'lactate')\n",
    "\n",
    "# Process Actions\n",
    "df_norepi = simplified_process_and_aggregate(df_actions, 'starttime', 'amount', ID_NOREPINEPHRINE, 'norepinephrine')\n",
    "df_fluids = simplified_process_and_aggregate(df_actions, 'starttime', 'amount', ID_FLUID_BOLUS, 'fluid_bolus')\n",
    "\n",
    "print(\"Cell 3: Data aggregation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2c8145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging features into a master DataFrame...\n",
      "Cell 4: Master DataFrame created.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3970 entries, 0 to 3969\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   stay_id         3970 non-null   int64  \n",
      " 1   time_bucket     3970 non-null   int64  \n",
      " 2   heart_rate      3122 non-null   float64\n",
      " 3   systolic_bp     2095 non-null   float64\n",
      " 4   diastolic_bp    2095 non-null   float64\n",
      " 5   temperature     2725 non-null   float64\n",
      " 6   lactate         1307 non-null   float64\n",
      " 7   norepinephrine  376 non-null    float64\n",
      " 8   fluid_bolus     1300 non-null   float64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 279.3 KB\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Merge into a Master DataFrame ---\n",
    "print(\"Merging features into a master DataFrame...\")\n",
    "dfs_to_merge = [df_hr, df_sbp, df_dbp, df_temp, df_lactate, df_norepi, df_fluids]\n",
    "\n",
    "# Start with the first DataFrame in the list as our base\n",
    "df_master = dfs_to_merge[0]\n",
    "\n",
    "# Loop through the rest of the DataFrames and merge them one by one\n",
    "for df_to_merge in dfs_to_merge[1:]:\n",
    "    df_master = pd.merge(df_master, df_to_merge, on=['stay_id', 'time_bucket'], how='outer')\n",
    "\n",
    "# Sort for chronological order\n",
    "df_master = df_master.sort_values(by=['stay_id', 'time_bucket']).reset_index(drop=True)\n",
    "\n",
    "print(\"Cell 4: Master DataFrame created.\")\n",
    "df_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d484a1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing data...\n",
      "Cell 5: Missing data handled, and index has been reset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivinm\\AppData\\Local\\Temp\\ipykernel_32952\\3975144854.py:6: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_master = df_master.groupby('stay_id').apply(lambda group: group.ffill()).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL CORRECTED Cell 5: Handle Missing Data ---\n",
    "print(\"Handling missing data...\")\n",
    "\n",
    "# This .apply() method correctly forward-fills within each group...\n",
    "# ...and .reset_index(drop=True) removes the ambiguous multi-index.\n",
    "df_master = df_master.groupby('stay_id').apply(lambda group: group.ffill()).reset_index(drop=True)\n",
    "\n",
    "# Fill any remaining NaNs (especially at the beginning of a stay) with 0\n",
    "df_master = df_master.fillna(0)\n",
    "\n",
    "print(\"Cell 5: Missing data handled, and index has been reset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea889ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting df_master just before the error ---\n",
      "\n",
      "First 5 rows:\n",
      "    stay_id  time_bucket  heart_rate  systolic_bp  diastolic_bp  temperature  \\\n",
      "0  30057454           -1         0.0          0.0           0.0         0.00   \n",
      "1  30057454            0       105.8          0.0           0.0        98.25   \n",
      "2  30057454            1       108.0          0.0           0.0        98.70   \n",
      "3  30057454            2       109.5          0.0           0.0        97.70   \n",
      "4  30057454            3       113.0          0.0           0.0        97.70   \n",
      "\n",
      "   lactate  norepinephrine  fluid_bolus  \n",
      "0      0.9             0.0     0.000000  \n",
      "1      0.9             0.0    17.916667  \n",
      "2      0.9             0.0    17.916667  \n",
      "3      0.9             0.0     7.000000  \n",
      "4      0.9             0.0    31.416668  \n",
      "\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3970 entries, 0 to 3969\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   stay_id         3970 non-null   int64  \n",
      " 1   time_bucket     3970 non-null   int64  \n",
      " 2   heart_rate      3970 non-null   float64\n",
      " 3   systolic_bp     3970 non-null   float64\n",
      " 4   diastolic_bp    3970 non-null   float64\n",
      " 5   temperature     3970 non-null   float64\n",
      " 6   lactate         3970 non-null   float64\n",
      " 7   norepinephrine  3970 non-null   float64\n",
      " 8   fluid_bolus     3970 non-null   float64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 279.3 KB\n",
      "\n",
      "\n",
      "Is 'stay_id' a column? -> True\n"
     ]
    }
   ],
   "source": [
    "# --- DEBUGGING CELL ---\n",
    "# Insert this cell right before the original Cell 6 to inspect the DataFrame\n",
    "\n",
    "print(\"--- Inspecting df_master just before the error ---\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_master.head())\n",
    "\n",
    "print(\"\\n\\nDataFrame Info:\")\n",
    "df_master.info()\n",
    "\n",
    "print(f\"\\n\\nIs 'stay_id' a column? -> {'stay_id' in df_master.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4b7f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final S_t, A_t, S_{t+1} table...\n",
      "Cell 6: Preprocessing complete!\n",
      "Created a final dataset with 3830 samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>time_bucket</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>lactate</th>\n",
       "      <th>norepinephrine</th>\n",
       "      <th>fluid_bolus</th>\n",
       "      <th>heart_rate_next</th>\n",
       "      <th>systolic_bp_next</th>\n",
       "      <th>diastolic_bp_next</th>\n",
       "      <th>temperature_next</th>\n",
       "      <th>lactate_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30057454</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.25</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30057454</td>\n",
       "      <td>0</td>\n",
       "      <td>105.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.25</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.916667</td>\n",
       "      <td>108.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.70</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30057454</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.70</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.916667</td>\n",
       "      <td>109.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30057454</td>\n",
       "      <td>2</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>113.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30057454</td>\n",
       "      <td>3</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.416668</td>\n",
       "      <td>110.75</td>\n",
       "      <td>82.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stay_id  time_bucket  heart_rate  systolic_bp  diastolic_bp  temperature  \\\n",
       "0  30057454           -1         0.0          0.0           0.0         0.00   \n",
       "1  30057454            0       105.8          0.0           0.0        98.25   \n",
       "2  30057454            1       108.0          0.0           0.0        98.70   \n",
       "3  30057454            2       109.5          0.0           0.0        97.70   \n",
       "4  30057454            3       113.0          0.0           0.0        97.70   \n",
       "\n",
       "   lactate  norepinephrine  fluid_bolus  heart_rate_next  systolic_bp_next  \\\n",
       "0      0.9             0.0     0.000000           105.80               0.0   \n",
       "1      0.9             0.0    17.916667           108.00               0.0   \n",
       "2      0.9             0.0    17.916667           109.50               0.0   \n",
       "3      0.9             0.0     7.000000           113.00               0.0   \n",
       "4      0.9             0.0    31.416668           110.75              82.5   \n",
       "\n",
       "   diastolic_bp_next  temperature_next  lactate_next  \n",
       "0                0.0             98.25           0.9  \n",
       "1                0.0             98.70           0.9  \n",
       "2                0.0             97.70           0.9  \n",
       "3                0.0             97.70           0.9  \n",
       "4               56.0             97.70           0.9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 6. Create Final S_t, A_t, S_{t+1} Table ---\n",
    "print(\"Creating final S_t, A_t, S_{t+1} table...\")\n",
    "state_cols = ['heart_rate', 'systolic_bp', 'diastolic_bp', 'temperature', 'lactate']\n",
    "action_cols = ['norepinephrine', 'fluid_bolus']\n",
    "\n",
    "# Create the \"next state\" columns by shifting the state columns up by one\n",
    "for col in state_cols:\n",
    "    df_master[f'{col}_next'] = df_master.groupby('stay_id')[col].shift(-1)\n",
    "\n",
    "# Drop the last row for each patient, as it has no \"next state\"\n",
    "df_final = df_master.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Cell 6: Preprocessing complete!\")\n",
    "print(f\"Created a final dataset with {len(df_final)} samples.\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9be4579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the world model...\n",
      "Cell 7: Training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Build and Train the World Model ---\n",
    "# X includes the state and action at time 't'\n",
    "X = df_final[state_cols + action_cols]\n",
    "# Y is the state at time 't+1'\n",
    "Y = df_final[[f'{col}_next' for col in state_cols]]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgbr = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Wrap it with MultiOutputRegressor to handle multiple targets\n",
    "multi_output_model = MultiOutputRegressor(estimator=xgbr)\n",
    "\n",
    "print(\"Training the world model...\")\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "print(\"Cell 7: Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebeee41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World model saved as 'world_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# --- Save the trained world model (XGBoost MultiOutputRegressor) ---\n",
    "import joblib\n",
    "\n",
    "joblib.dump(multi_output_model, 'world_model.pkl')\n",
    "print(\"World model saved as 'world_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38971360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Evaluate the World Model ---\n",
    "print(\"Evaluating the world model...\")\n",
    "y_pred = multi_output_model.predict(X_test)\n",
    "\n",
    "# Calculate overall Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"\\nOverall World Model MSE on Test Set: {mse:.4f}\")\n",
    "\n",
    "# You can also look at the error for each variable individually\n",
    "print(\"\\n--- MSE for each predicted variable ---\")\n",
    "for i, col in enumerate(state_cols):\n",
    "    var_mse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i])\n",
    "    print(f\"  - MSE for {col}_next: {var_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class PatientSimulatorEnv(gym.Env):\n",
    "    \"\"\"A custom Gym environment for simulating patient treatment.\"\"\"\n",
    "    \n",
    "    def __init__(self, world_model, initial_states_df, state_cols, action_cols):\n",
    "        super(PatientSimulatorEnv, self).__init__()\n",
    "        \n",
    "        self.world_model = world_model\n",
    "        self.initial_states = initial_states_df[state_cols].values\n",
    "        self.state_cols = state_cols\n",
    "        self.action_cols = action_cols\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example: 5 discrete levels for norepinephrine, 5 for fluids = 25 actions\n",
    "        self.action_space = spaces.Discrete(25) \n",
    "        \n",
    "        # The state space is continuous\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, \n",
    "                                            shape=(len(state_cols),), dtype=np.float32)\n",
    "        \n",
    "        self.current_state = None\n",
    "        self.episode_length = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Randomly select an initial state from the real data\n",
    "        initial_state_idx = np.random.randint(0, len(self.initial_states))\n",
    "        self.current_state = self.initial_states[initial_state_idx]\n",
    "        self.episode_length = 0\n",
    "        \n",
    "        return self.current_state, {} # Return state and an empty info dict\n",
    "\n",
    "    def step(self, action):\n",
    "        # 1. Decode the discrete action into medication dosages\n",
    "        # Example: action #15 -> level 3 norepi, level 3 fluids\n",
    "        # This requires you to define a mapping.\n",
    "        # For now, let's assume a placeholder for the action vector.\n",
    "        action_vector = np.zeros(len(self.action_cols)) # Placeholder\n",
    "        \n",
    "        # 2. Prepare the input for the world model\n",
    "        model_input = np.concatenate([self.current_state, action_vector]).reshape(1, -1)\n",
    "        \n",
    "        # 3. Use the world model to predict the next state\n",
    "        previous_lactate = self.current_state[self.state_cols.index('lactate')] # Get lactate before the step\n",
    "        predicted_next_state = self.world_model.predict(model_input)[0]\n",
    "        self.current_state = predicted_next_state\n",
    "        self.episode_length += 1\n",
    "        \n",
    "        # 4. Calculate the reward and determine if the episode is done\n",
    "        new_lactate = self.current_state[self.state_cols.index('lactate')]\n",
    "        \n",
    "        terminated = False\n",
    "        \n",
    "        # Reward is based on the change in lactate from the previous state\n",
    "        reward = (previous_lactate - new_lactate) * 10 # Reward for reducing lactate\n",
    "\n",
    "        \n",
    "        # Add large penalties/rewards for terminal states\n",
    "        if new_lactate > 4.0:\n",
    "            reward -= 100 # Large penalty for critical state\n",
    "            terminated = True\n",
    "        elif new_lactate < 1.0 and self.episode_length > 5: # Give a bonus for stabilizing\n",
    "             reward += 50\n",
    "             terminated = True\n",
    "            \n",
    "        if self.episode_length >= 50:\n",
    "            terminated = True\n",
    "            \n",
    "        return self.current_state, reward, terminated, False, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "# 1. Create an instance of your environment\n",
    "# We use the 'X' DataFrame from the previous step to get initial states\n",
    "env = PatientSimulatorEnv(multi_output_model, X, state_cols, action_cols)\n",
    "\n",
    "# 2. Instantiate the DQN agent\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# 3. Train the agent\n",
    "# This will take some time. The agent will play out thousands of episodes in the simulator.\n",
    "print(\"Training RL agent...\")\n",
    "model.learn(total_timesteps=1000000, progress_bar=True)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2652274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate the trained agent ---\n",
    "episodes = 10\n",
    "total_reward = 0\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        ep_reward += reward\n",
    "    \n",
    "    total_reward += ep_reward\n",
    "    print(f\"Episode {ep + 1}: Total Reward = {ep_reward}\")\n",
    "\n",
    "avg_reward = total_reward / episodes\n",
    "print(f\"\\nAverage reward over {episodes} episodes: {avg_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the trained model ---\n",
    "model.save(\"dqn_mimic_patient_model_v1\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
